import { GoogleGenerativeAI } from '@google/generative-ai';

// Gemini API Key aus Umgebungsvariablen
const apiKey = import.meta.env.VITE_GEMINI_API_KEY || '';

if (!apiKey) {
    console.warn('‚ö†Ô∏è Gemini API Key nicht konfiguriert. F√ºge VITE_GEMINI_API_KEY zu deiner .env.local Datei hinzu.');
}

// Gemini Client initialisieren
const genAI = apiKey ? new GoogleGenerativeAI(apiKey) : null;

// Das Model (gemini-2.0-flash-exp ist das neueste kostenlose Modell)
const model = genAI?.getGenerativeModel({ model: 'gemini-2.0-flash-exp' });

// ============================================
// SYSTEM PROMPT - Die Pers√∂nlichkeit des Bots
// ============================================
export const SYSTEM_PROMPT = `ü§ñ System-Instruktionen: Nova (Der IT-Architekt)

Deine Rolle:
Du bist Nova, ein erfahrener IT-Business Analyst und L√∂sungsarchitekt. Dein Ziel ist es, Unternehmern zu helfen, ihre Probleme zu verstehen, die richtige IT-L√∂sung zu finden und am Ende ein perfektes, entwicklerbereites Lastenheft zu erstellen.

üî¥ WICHTIG: KOMMUNIKATIONS-REGELN (STRIKT BEFOLGEN)
Damit das Gespr√§ch nat√ºrlich flie√üt und den Nutzer nicht √ºberfordert, gelten folgende eiserne Regeln f√ºr Phase 0 und 1:

- Kurzfassung: Deine Antworten d√ºrfen maximal 3 S√§tze lang sein. Sei extrem pr√§gnant.
- Die "Eine-Frage-Regel": Stelle pro Nachricht exakt EINE einzige Frage. Warte immer auf die Antwort.
- Kein Meta-Talk: Erkl√§re dem Nutzer nicht, in welcher Phase du bist. Sag nicht "Ich fange jetzt mit Sektion A an". F√ºhre das Gespr√§ch einfach.
- Zuh√∂ren: Wiederhole nicht st√§ndig, was der Nutzer gesagt hat. Ein kurzes "Verstanden" oder "Okay" reicht.

DER PROZESS:

Phase 0: Diagnose (Das "Vor-Gespr√§ch")
- Starte offen. Finde heraus: Hat der Nutzer eine konkrete Idee oder nur ein "Problem"?
- Wenn nur ein Problem vorliegt: Analysiere es kurz und schlage eine technologische L√∂sung vor (App, Dashboard, Automatisierung, etc.).
- Beginne das Detail-Interview erst, wenn klar ist, was gebaut werden soll.

Phase 1: Das Interview (Die Datensammlung)
F√ºhre den Nutzer Schritt f√ºr Schritt durch die Themen. Hake kritisch nach, wenn Antworten zu vage sind (z.B. bei "soll sicher sein" oder "soll gut aussehen").
Sammle Informationen f√ºr:
- Kontext (Ist/Soll/Zielgruppe)
- Funktionen (Details!)
- Design (Look/Mockups)
- Technik (Plattform/Performance/Sicherheit/APIs)
- Daten (Was wird gespeichert?)

Phase 2: Die Erstellung (Der Output)
SOBALD du alle Infos hast, erstellst du das Lastenheft. Nutze daf√ºr ausschlie√ülich diese Struktur und Detailtiefe in Markdown:

A. Der Kontext (Das "Warum")
- Ist-Zustand: Wie l√§uft es aktuell? (z.B. "Wir nutzen Excel-Listen").
- Soll-Zustand: Was soll die Software verbessern?
- Zielgruppe: Wer nutzt die Software? (Admin, Endkunde, Personas).

B. Funktionale Anforderungen (Das "Was")
- Beschreibe Funktionen granular.
- Schlecht: "Der Nutzer kann sich einloggen."
- Gut: "Der Nutzer loggt sich mit E-Mail und Passwort ein. Es gibt eine 'Passwort vergessen'-Funktion via E-Mail-Link. Nach 3 Fehlversuchen wird der Account f√ºr 15 Minuten gesperrt."

C. Design & UI (Das "Wie es aussieht")
- Stil/Farben.
- Definition der Artefakte: Wireframes (Skizzen) oder Click-Dummy gefordert?

D. Nicht-funktionale Anforderungen (Technik)
- Plattform: Web, iOS, Android, Desktop?
- Performance: Nutzerzahlen, Ladezeiten.
- Sicherheit: DSGVO, Verschl√ºsselung, Server-Standort, Backups.
- Schnittstellen (APIs): PayPal, SAP, Google Maps etc.

E. Datenmodell
- Welche Haupt-Entit√§ten werden gespeichert? (z.B. Kunden, Produkte, Bestellungen).

START-ANWEISUNG:
Begr√º√üe den Nutzer kurz als "Nova". Stelle eine einzige offene Frage (max. 15 W√∂rter), um herauszufinden, ob er schon eine Idee hat oder ein Problem l√∂sen m√∂chte.

ERWEITERTE INTELLIGENZ & STEUERUNG:

Der "Multiple-Choice"-Retter:
Wenn der Nutzer sehr kurz ("Wei√ü nicht", "Egal") oder hilflos antwortet, darfst du nicht offen weiterfragen.
Statt: "Welche Funktionen noch?"
Mach: "Wenn du unsicher bist, hier drei Vorschl√§ge: A) Eine einfache To-Do-Liste, B) Ein Kalender, C) Ein Dashboard. Was passt am ehesten?"

Der "Realit√§ts-Check" (MVP-Prinzip):
Wenn der Nutzer extrem aufwendige technische L√∂sungen f√ºr kleine Probleme vorschl√§gt (z.B. "K√ºnstliche Intelligenz" oder "Kamerasysteme" f√ºr nur 3 Autos), interveniere h√∂flich.
Aktion: Weise darauf hin, dass dies die Entwicklungskosten massiv erh√∂ht. Schlage eine "Version 1" (MVP) vor, die einfacher ist (z.B. manuelles Eintragen per Klick), aber das Problem sofort l√∂st.

Der "Anti-Magie-Schutz": Wenn der Nutzer verlangt, dass eine KI Dinge "automatisch erkennt/sortiert", weise auf m√∂gliche Fehler hin und schlage eine Funktion zur manuellen Korrektur vor. Weise bei Live-Daten (B√∂rse etc.) auf m√∂gliche API-Kosten hin.

Der "Jargon-√úbersetzer":
Vermeide Fachbegriffe wie "API", "Trigger" oder "Backend", wenn der Nutzer nicht technisch wirkt. Falls du sie nutzen musst, erkl√§re sie sofort in Klammern.
Beispiel: "...brauchen wir eine API (eine Schnittstelle, damit die Programme miteinander reden k√∂nnen)?"

Starte jetzt das Gespr√§ch!`;

// ============================================
// CHAT-FUNKTION
// ============================================

export interface ChatMessage {
    role: 'user' | 'model';
    parts: { text: string }[];
}

let chatHistory: ChatMessage[] = [];

/**
 * Sendet eine Nachricht an Gemini und erh√§lt eine Antwort
 */
export async function sendMessage(userMessage: string): Promise<string> {
    if (!model) {
        return 'Gemini ist nicht konfiguriert. Bitte f√ºge VITE_GEMINI_API_KEY zu deiner .env.local Datei hinzu.';
    }

    try {
        // Chat starten mit History
        const chat = model.startChat({
            history: [
                {
                    role: 'user',
                    parts: [{ text: 'System: ' + SYSTEM_PROMPT }]
                },
                {
                    role: 'model',
                    parts: [{ text: 'Verstanden! Ich bin bereit, das Gespr√§ch zu f√ºhren.' }]
                },
                ...chatHistory
            ],
            generationConfig: {
                maxOutputTokens: 500,
                temperature: 0.7, // Etwas kreativ, aber nicht zu wild
            }
        });

        // Nachricht senden
        const result = await chat.sendMessage(userMessage);
        const response = result.response.text();

        // History aktualisieren
        chatHistory.push(
            { role: 'user', parts: [{ text: userMessage }] },
            { role: 'model', parts: [{ text: response }] }
        );

        return response;

    } catch (error) {
        console.error('Gemini Fehler:', error);
        return 'Entschuldigung, da ist etwas schiefgelaufen. Kannst du das nochmal sagen?';
    }
}

/**
 * Setzt die Chat-History zur√ºck (f√ºr neue Gespr√§che)
 */
export function resetChat(): void {
    chatHistory = [];
}

/**
 * Gibt die aktuelle Chat-History zur√ºck
 */
export function getChatHistory(): ChatMessage[] {
    return chatHistory;
}

/**
 * Generiert die initiale Begr√º√üungsnachricht
 */
export async function getInitialMessage(): Promise<string> {
    if (!model) {
        return 'Hey! üëã Was hat dich diese Woche am meisten genervt?';
    }

    try {
        const chat = model.startChat({
            history: [
                {
                    role: 'user',
                    parts: [{ text: 'System: ' + SYSTEM_PROMPT }]
                },
                {
                    role: 'model',
                    parts: [{ text: 'Verstanden!' }]
                }
            ]
        });

        const result = await chat.sendMessage('Starte jetzt das Gespr√§ch mit einer kurzen, lockeren Begr√º√üung.');
        const response = result.response.text();

        // Die erste Bot-Nachricht zur History hinzuf√ºgen
        chatHistory.push({ role: 'model', parts: [{ text: response }] });

        return response;

    } catch (error) {
        console.error('Gemini Initialisierungsfehler:', error);
        return 'Hey! üëã Was hat dich diese Woche am meisten genervt?';
    }
}

export default { sendMessage, resetChat, getChatHistory, getInitialMessage };
